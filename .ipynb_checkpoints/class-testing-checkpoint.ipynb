{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c6060e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "45e35971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinomialExperiment():\n",
    "    \"\"\"\n",
    "    Creates an object that represents observed or desired split test results.\n",
    "    Currently only supports two-way split tests. n-way tests will be supported\n",
    "    in a future release.\n",
    "\n",
    "    Analyses can then be performed on this object by calling this class's methods.\n",
    "    Return statistical power, estimate a necessary sample size, return statistical\n",
    "    significance. Plotting is also possible.\n",
    "\n",
    "    Marketing program/campaign optimizaiton is the intended use case. Therefore,\n",
    "    split tests are evaluated with one-way significance tests and under these hypotheses:\n",
    "\n",
    "    Null: Treatment Probability - Control Probability <= 0\n",
    "    Alt: Treatment Probability - Control Probability > 0\n",
    "\n",
    "    Also, this class is designed to be used as the backend of a web application\n",
    "    that helps marketers plan and understand optimization experiments.\n",
    "    \"\"\"\n",
    "    def __init__(self, p_control, p_treatment, n_control = None, n_treatment = None, power = None, alpha = 0.05):\n",
    "        \"\"\"\n",
    "        Only two required args are p_control and p_treatment. It is assumed that the user is either evaluating a completed\n",
    "        experiment or has already determined the practical difference necessary to make an experiment's results worthwhile.\n",
    "        \n",
    "        So, those two values are already on-hand.\n",
    "        \"\"\"\n",
    "        self.p_control = p_control\n",
    "        self.p_treatment = p_treatment\n",
    "        \n",
    "        self.n_control = n_control\n",
    "        self.n_treatment = n_treatment\n",
    "        \n",
    "        self.var_control = 1 * p_control * (1 - p_control)\n",
    "        self.var_treatment = 1 * p_treatment * (1 - p_treatment)\n",
    "        \n",
    "        if power == 1:\n",
    "            print('Sample size approaches infinity as power approaches 1, so 1 is an invalid power vlaue. Changing power to 0.99.')\n",
    "            self.power = 0.99\n",
    "        elif power == 0:\n",
    "            print('Sample size is undefined at power of 0. Changing power to 0.01.')\n",
    "            self.power = 0.01\n",
    "        else:\n",
    "            self.power = power\n",
    "            \n",
    "        self.alpha = alpha\n",
    "        self.p_value = None\n",
    "        \n",
    "    def get_p_sample(self):\n",
    "        \"\"\"\n",
    "        Take sample sizes and probabilities from each sample and return the probability of the combination of samples\n",
    "        \"\"\"\n",
    "        control = self.p_control * self.n_control\n",
    "        treatment = self.p_treatment * self.n_treatment\n",
    "        sample = self.n_control + self.n_treatment\n",
    "        \n",
    "        p_sample = (control + treatment) / sample\n",
    "        \n",
    "        self.p_sample = p_sample\n",
    "        \n",
    "        return p_sample\n",
    "        \n",
    "    def estimate_sample(self):\n",
    "        \"\"\"\n",
    "        Take desired effect size, alpha and desired power level. Return a minimum sample size (one group)\n",
    "        that would be necessary to acheive the desired experiment results.\n",
    "        \n",
    "        Allows the user to specify power and alpha here, if they didn't specify them when they instantiated the class.\n",
    "        Otherwise, it takes the values provided to the class on instantiation.\n",
    "        \"\"\"\n",
    "        z_null = stats.norm.ppf(1 - self.alpha)\n",
    "        z_alt = stats.norm.ppf(1 - self.power)\n",
    "        \n",
    "        stdev_null = np.sqrt(self.var_control + self.var_control)\n",
    "        stdev_alt = np.sqrt(self.var_control + self.var_treatment)\n",
    "        \n",
    "        z_diff = (z_null * stdev_null) - (z_alt * stdev_alt)\n",
    "        p_diff = self.p_treatment - self.p_control\n",
    "        \n",
    "        n = (z_diff / p_diff) ** 2\n",
    "        \n",
    "        sample_size = int(np.ceil(n))\n",
    "        \n",
    "        self.n_control = sample_size\n",
    "        self.n_treatment = sample_size\n",
    "        \n",
    "        return n\n",
    "    \n",
    "    def analyze_significance(self):\n",
    "        \"\"\"\n",
    "        Take sample sizes and probabilities and return the significance of the difference between the probabilities.\n",
    "        One-tailed test.\n",
    "        \n",
    "        Null: Treatment Prob - Control Prob <= 0\n",
    "        Alt: Treatment Prob - Control Prob > 0\n",
    "        \"\"\"\n",
    "        var_control = 1 * self.p_sample * (1 - self.p_sample)\n",
    "        var_treatment = 1 * self.p_sample * (1 - self.p_sample) # Same as var_control, because null hyp is no difference\n",
    "        \n",
    "        sigma = np.sqrt((var_control / self.n_control) + (var_treatment / self.n_treatment))\n",
    "        \n",
    "        z = (self.p_treatment - self.p_control) / sigma\n",
    "        p = (1 - stats.norm.cdf(z))\n",
    "        self.p_value = p\n",
    "        \n",
    "        return p\n",
    "    \n",
    "    def simulate_significance(self):\n",
    "        \"\"\"\n",
    "        Same intent and outcome as analyze_significance(), but it simulates a binomial distribution rather than\n",
    "        approximating one with a normal distribution. No continuity correction, necessary. Only significant source of\n",
    "        inaccuracy would be variability between runs (random simulations can yield slightly different outcomes, each time).\n",
    "        \"\"\"\n",
    "        observed_difference = self.p_treatment - self.p_control\n",
    "        \n",
    "        rng = np.random.default_rng()\n",
    "        sample_control = rng.binomial(n = self.n_control, p = self.p_sample, size = 1000000) / self.n_control\n",
    "        sample_treatment = rng.binomial(n = self.n_treatment, p = self.p_sample, size = 1000000) / self.n_treatment\n",
    "        \n",
    "        differences = sample_treatment - sample_control\n",
    "        \n",
    "        p = (differences >= observed_difference).mean()\n",
    "        self.p_value = p\n",
    "        \n",
    "        return p\n",
    "    \n",
    "    def simulate_power(self):\n",
    "        \"\"\"\n",
    "        Takes results of a completed experiment and reveals the statistical power of the significance conclusion.\n",
    "        \"\"\"\n",
    "        if self.p_treatment - self.p_control < 0:\n",
    "            print('Alt Hypothesis: Treatment - Control < 0\\n')\n",
    "            thresh = 1 - self.alpha\n",
    "        else:\n",
    "            print('Alt Hypothesis: Treatment - Control > 0\\n')\n",
    "            thresh = self.alpha\n",
    "            \n",
    "        sterror_null = np.sqrt((self.var_control / self.n_control) + (self.var_control / self.n_control))\n",
    "        sterror_alt =  np.sqrt((self.var_treatment / self.n_treatment) + (self.var_control / self.n_control))\n",
    "        \n",
    "        dist_null = stats.norm(loc = 0, scale = sterror_null)\n",
    "        dist_alt = stats.norm(loc = self.p_treatment - self.p_control, scale = sterror_alt)\n",
    "        \n",
    "        p_crit = dist_null.ppf(1 - thresh)\n",
    "        beta = dist_alt.cdf(p_crit)\n",
    "        \n",
    "        power = (1 - beta) if self.p_treatment > self.p_control else beta\n",
    "        self.power = power\n",
    "            \n",
    "        return power\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Magic method that outputs the experiment's parameters, so far.\n",
    "        \"\"\"\n",
    "        header = '|||Experiment Readout|||\\n'\n",
    "        data = [['Control Probability', '{:.2%}'.format(self.p_control)],\n",
    "               ['Treatment Probability', '{:.2%}'.format(self.p_treatment)],\n",
    "               ['Effect Size', '{:.2%}'.format(self.p_treatment - self.p_control)],\n",
    "               ['',''], \n",
    "               ['Control Sample Size', '{:,}'.format(self.n_control)],\n",
    "               ['Treatment Sample Size', '{:,}'.format(self.n_treatment)],\n",
    "               ['',''],\n",
    "               ['Statistical Power', '{:.3f}'.format(self.power)],\n",
    "               ['Significance Threshold', '{:.3f}'.format(self.alpha)],\n",
    "               ['P Value', '{:.3f}'.format(self.p_value) if self.p_value else 'None']]\n",
    "\n",
    "        return header + str(pd.DataFrame(data = [x[1] for x in data], index = [x[0] for x in data], columns = ['']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "835ff06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = BinomialExperiment(p_control = 0.1, p_treatment = 0.12, power = 0.8, alpha = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "6da0df2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2862.6432162617175"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.estimate_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "dbaafd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.get_p_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "dbc9b8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007793726228646269"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.analyze_significance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "76657fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007531"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.simulate_significance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "50f46769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "|||Experiment Readout|||\n",
       "                              \n",
       "Control Probability     10.00%\n",
       "Treatment Probability   12.00%\n",
       "Effect Size              2.00%\n",
       "                              \n",
       "Control Sample Size      2,863\n",
       "Treatment Sample Size    2,863\n",
       "                              \n",
       "Statistical Power        0.800\n",
       "Significance Threshold   0.050\n",
       "P Value                  0.008"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "93fa377f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alt Hypothesis: Treatment - Control > 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8000422080114082"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.simulate_power()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ff18969c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "|||Experiment Readout|||\n",
       "                              \n",
       "Control Probability     10.00%\n",
       "Treatment Probability   12.00%\n",
       "Effect Size              2.00%\n",
       "                              \n",
       "Control Sample Size      2,863\n",
       "Treatment Sample Size    2,863\n",
       "                              \n",
       "Statistical Power        0.800\n",
       "Significance Threshold   0.050\n",
       "P Value                  0.008"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "datasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
