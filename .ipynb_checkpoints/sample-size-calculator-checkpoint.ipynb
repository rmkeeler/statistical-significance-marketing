{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate test variables\n",
    "prob_control = 0.10\n",
    "prob_treatment = 0.12\n",
    "\n",
    "size_control = 1000\n",
    "size_treatment = 1000\n",
    "\n",
    "alpha = 0.05 # Allowance for type 1 error. P value significance threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypotheses\n",
    "\n",
    "**Null:** Control and treatment samples are part of the same binomial distribution. Treatment prob - Control prob <= 0.\n",
    "\n",
    "**Alt:** Treatment sample is part of a binomial distribution with mean higher than that of control. Treatment prob - Control prob > 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Derive Stat Power from Probs and Sample Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1a: Simulation Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get variances of binomial variables based on treatment and control probs\n",
    "# REMEMBER: variance of binomial variable is k(p)(1-p), where k is count of trials\n",
    "# In a marketing experiment trial count per sample member is 1 (only one chance to click or not per member)\n",
    "# In light of hypotheses, we need to consider both control and treatment as parts of the same distribution\n",
    "# So, we combine their binomial distributions Control + Treatment\n",
    "# Variances are likewise added Var(Treatment) + Var(Control)\n",
    "variance_control = 1 * prob_control * (1 - prob_control)\n",
    "variance_treatment = 1 * prob_treatment * (1 - prob_treatment)\n",
    "variance_null = variance_control + variance_treatment\n",
    "\n",
    "# Get standard error of null distribution\n",
    "# Using control for both elements of calculation, because null hypothesis is that Treatment + Control is same as Control + Control\n",
    "# Both treatment and control are parts of equivalent binomial distributions\n",
    "sterror_null = np.sqrt((variance_control / size_control) + (variance_control / size_control))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical Difference: 0.022068027137403433\n"
     ]
    }
   ],
   "source": [
    "# Get the null binomial distribution\n",
    "null_dist = stats.norm(loc = 0, scale = sterror_null)\n",
    "p_crit = null_dist.ppf(1 - alpha)\n",
    "print(\"Critical Difference: {}\".format(p_crit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get standard error of alt distribution (assumes treatment - prob is mean of its own separate binomial variable)\n",
    "sterror_alt = np.sqrt((variance_control / size_control) + (variance_treatment / size_treatment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat Power: 0.44122379261151545\n"
     ]
    }
   ],
   "source": [
    "# Get the alt binomial distribution\n",
    "alt_dist = stats.norm(loc = prob_treatment - prob_control, scale = sterror_alt)\n",
    "beta = alt_dist.cdf(p_crit) # cumulative distribution function. Proportion of values in distribution below given value.\n",
    "stat_power = 1 - beta # inverts beta to get proportion of values in alt_dist above p_crit\n",
    "\n",
    "print(\"Stat Power: {}\".format(stat_power))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Derive Sample Size from Stat Power and Probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2a: Analytic Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great Notes from Udacity Instructor with Additions from Me\n",
    "\n",
    "Now that we've got some intuition for power by using trial and error, we can now approach a closed-form solution for computing a minimum experiment size. The key point to notice is that, for an $\\alpha$ and $\\beta$ both < .5, the critical value for determining statistical significance will fall between our null click-through rate and our alternative, desired click-through rate. So, the difference between $p_0$ and $p_1$ can be subdivided into the distance from $p_0$ to the critical value $p^*$ and the distance from $p^*$ to $p_1$.\n",
    "\n",
    "<img src= 'https://viewvrgyb1g8sx9.udacity-student-workspaces.com/files/images/ExpSize_Power.png'>\n",
    "\n",
    "Those subdivisions can be expressed in terms of the standard error and the z-scores:\n",
    "**Ryan Note:** These formulae skip a bunch of algebraic simplification. Z score calculation starts like this:\n",
    "\n",
    "$$z_{observed} = \\frac{(p_{observed} - p_{mean})}{SE_{mean}}$$\n",
    "\n",
    "$$p^* - p_0 = z_{1-\\alpha} SE_{0},$$\n",
    "$$p_1 - p^* = -z_{\\beta} SE_{1};$$\n",
    "\n",
    "$$p_1 - p_0 = z_{1-\\alpha} SE_{0} - z_{\\beta} SE_{1}$$\n",
    "\n",
    "In turn, the standard errors can be expressed in terms of the standard deviations of the distributions, divided by the square root of the number of samples in each group:\n",
    "\n",
    "$$SE_{0} = \\frac{s_{0}}{\\sqrt{n}},$$\n",
    "$$SE_{1} = \\frac{s_{1}}{\\sqrt{n}}$$\n",
    "\n",
    "Substituting these values in and solving for $n$ will give us a formula for computing a minimum sample size to detect a specified difference, at the desired level of power:\n",
    "\n",
    "$$n = \\lceil \\big(\\frac{z_{\\alpha} s_{0} - z_{\\beta} s_{1}}{p_1 - p_0}\\big)^2 \\rceil$$\n",
    "\n",
    "where $\\lceil ... \\rceil$ represents the ceiling function, rounding up decimal values to the next-higher integer. Implement the necessary variables in the function below, and test them with the cells that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify inputs\n",
    "alpha = 0.05\n",
    "power = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Sig Level: 0.05\n",
      "Target Power: 0.8\n",
      "Target Group Size: 1,613\n",
      "Target Experiment Size: 3,226\n"
     ]
    }
   ],
   "source": [
    "z_null = stats.norm.ppf(1-alpha)\n",
    "z_alt = stats.norm.ppf(power)\n",
    "\n",
    "stdev_null = np.sqrt((prob_control * (1 - prob_control)) + (prob_control * (1 - prob_control)))\n",
    "stdev_alt = np.sqrt((prob_control * (1 - prob_control)) + (prob_treatment * (1 - prob_treatment)))\n",
    "\n",
    "z_diff = z_null - z_alt\n",
    "p_diff = treatment_prob - control_prob\n",
    "\n",
    "n = int(np.ceil((z_diff / p_diff) ** 2))\n",
    "\n",
    "print(\"Target Sig Level: {}\".format(alpha))\n",
    "print(\"Target Power: {}\".format(power))\n",
    "print(\"Target Group Size: {:,}\".format(n))\n",
    "print(\"Target Experiment Size: {:,}\".format(2*n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
